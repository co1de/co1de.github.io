<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>co1de&#39;s blogs</title>
  
  <subtitle>记录个人工作生活</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-06-03T14:42:37.625Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>co1de</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>在XenServer环境下搭建Hadoop集群</title>
    <link href="http://yoursite.com/2019/06/03/%E5%9C%A8XenServer%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%90%AD%E5%BB%BAHadoop%E9%9B%86%E7%BE%A4/"/>
    <id>http://yoursite.com/2019/06/03/在XenServer环境下搭建Hadoop集群/</id>
    <published>2019-06-03T13:54:00.000Z</published>
    <updated>2019-06-03T14:42:37.625Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Jun 03 2019 22:43:00 GMT+0800 (中国标准时间) --><h2 id="一些旧文章，因为一些原因内容有删减，发出来鞭尸。"><a href="#一些旧文章，因为一些原因内容有删减，发出来鞭尸。" class="headerlink" title="一些旧文章，因为一些原因内容有删减，发出来鞭尸。"></a>一些旧文章，因为一些原因内容有删减，发出来鞭尸。</h2><h1 id="0-工具及环境"><a href="#0-工具及环境" class="headerlink" title="0.工具及环境"></a>0.工具及环境</h1><p>环境：实验室服务器，装有xenserver，虚拟节点为centos<br>工具：windows下Xencenter，自动化部署安装Ambari脚本</p><h1 id="1-安装centos虚拟机"><a href="#1-安装centos虚拟机" class="headerlink" title="1.安装centos虚拟机"></a>1.安装centos虚拟机</h1><p>首先在服务器上安装centos虚拟机，将服务器划开。</p><h2 id="1-1-windows下共享iso文件夹"><a href="#1-1-windows下共享iso文件夹" class="headerlink" title="1.1 windows下共享iso文件夹"></a>1.1 windows下共享iso文件夹</h2><p>XenServer 定义了一个名为存储库(SR) 的容器来描述存储虚拟磁盘映像 (VDI) 的特定存储目标。<br>XenServer不同于VM可以直接导入iso，在windows环境下需要使用共享文件夹的方式共享iso，在linux环境下需要使用nfs的方式共享iso。这里我们都是在windows环境下管理，因此记录下windows下的管理方式。<br>选择存有iso的文件夹进行共享。<br><img src="\images\pasted-14.png" alt="upload successful"></p><h2 id="1-2-在XenCenter中新建SR"><a href="#1-2-在XenCenter中新建SR" class="headerlink" title="1.2 在XenCenter中新建SR"></a>1.2 在XenCenter中新建SR</h2><h3 id="1-2-1-首先需要先新建一个sr"><a href="#1-2-1-首先需要先新建一个sr" class="headerlink" title="1.2.1 首先需要先新建一个sr"></a>1.2.1 首先需要先新建一个sr</h3><p><img src="\images\pasted-15.png" alt="upload successful"></p><h3 id="1-2-2-选择iso库中的windows文件共享"><a href="#1-2-2-选择iso库中的windows文件共享" class="headerlink" title="1.2.2 选择iso库中的windows文件共享"></a>1.2.2 选择iso库中的windows文件共享</h3><p><img src="\images\pasted-16.png" alt="upload successful"></p><h3 id="1-2-3-注意网络位置"><a href="#1-2-3-注意网络位置" class="headerlink" title="1.2.3 注意网络位置"></a>1.2.3 注意网络位置</h3><p>直接复制过来的共享路径可能无法解析dns，最好将主机名改为ip。账号登陆是为了安全，一般用当前windows账号就可以。<br><img src="\images\pasted-17.png" alt="upload successful"><br>如果使用的是<strong>微软帐号</strong>登陆，请使用邮箱和密码登陆。</p><p><img src="\images\pasted-18.png" alt="upload successful"><br>连接成功后我们可以在侧边栏看到新添加的库</p><p><img src="\images\pasted-19.png" alt="upload successful"></p><h3 id="1-2-4-可能出现的问题"><a href="#1-2-4-可能出现的问题" class="headerlink" title="1.2.4 可能出现的问题"></a>1.2.4 可能出现的问题</h3><p>在新建sr中可能会出现连接不上的问题，这里给出几个参考，可以尝试能否解决。</p><ul><li>检查windows smb服务<br>本人的连接问题即windows 10更新后smb服务默认是没开启的，各种连不上，开启服务后一切正常。<br>步骤：控制面板-&gt;程序-&gt;启用或关闭windows功能<br>若没有开启勾选安装完成后重启即可。</li></ul><p><img src="\images\pasted-20.png" alt="upload successful"></p><ul><li>检查组策略编辑器<br>本人问题是在第一个方法完成后就解决了，这里方法仅供参考。<br>运行gpedit.msc<br><img src="\images\pasted-21.png" alt="upload successful"><br>检查框选的两个部分，第一个部分中应有前面要登陆的账户，没有则添加，第二个部分可以选择清空处理。<h2 id="1-3-开始安装虚拟机"><a href="#1-3-开始安装虚拟机" class="headerlink" title="1.3 开始安装虚拟机"></a>1.3 开始安装虚拟机</h2><h3 id="1-3-1-准备安装环境"><a href="#1-3-1-准备安装环境" class="headerlink" title="1.3.1 准备安装环境"></a>1.3.1 准备安装环境</h3>这里我们可以不用已有模板，选择最后的other install media，这样可以使用图形化界面进行安装。</li></ul><p><img src="\images\pasted-22.png" alt="upload successful"><br>这里我们可以选择刚才添加的iso库。</p><p><img src="\images\pasted-23.png" alt="upload successful"><br>后面的步骤省略，都为自定义配置部分。<br>配置完毕后可在vm的控制台中配置安装过程。</p><blockquote><p>一个问题：<br>使用other install media 模板。每次都停在 mounting /tmp as tmpfs… done<br>谷歌路径;<a href="javascript:void(" target="_blank" rel="noopener">http://serverfault.com/questions/535492/rhel-clones-centos-scientific-cern-network-installation-on-xenserver-6-2</a>) 里找到答案。<br>解决方案：<br>进入Xenserver宿主机，<br>首先通过xe vm-list获取UUID<br>然后再执行xe vm-param-set uuid=uuid_of_your_virtual_machine platform:viridian=false<br>接着重新启动你要安装的那个系统</p></blockquote><h3 id="1-3-2-配置系统参数"><a href="#1-3-2-配置系统参数" class="headerlink" title="1.3.2 配置系统参数"></a>1.3.2 配置系统参数</h3><p>安装过程省略。</p><h3 id="1-3-3-安装xentool"><a href="#1-3-3-安装xentool" class="headerlink" title="1.3.3 安装xentool"></a>1.3.3 安装xentool</h3><p>为方便管理，可考虑安装xentool，它还有其余优化功能,比如在网络连接里可以看到ip地址等，此处不赘述<br></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/cdrom /mnt</span><br><span class="line">/mnt/Linux/install.sh</span><br></pre></td></tr></table></figure><p></p><h3 id="1-3-4-配置网络"><a href="#1-3-4-配置网络" class="headerlink" title="1.3.4 配置网络"></a>1.3.4 配置网络</h3><p>配置文件路径在 /etc/sysconfig/network-scripts/ 下，找到想使用的默认网卡，进入修改配置。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=eth0</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">UUID=81a678ea-81fa-4015-b6be-edea9f1c1ec3</span><br><span class="line">ONBOOT=yes  #需要设置为yes，否则找不到网卡</span><br><span class="line">NM_CONTROLLED=yes</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">IPADDR=192.168.0.51</span><br><span class="line">#基本上PREFIX = 16与NETMASK 255.255.0.0相同，PREFIX = 24与NETMASK 255.255.255.0相同</span><br><span class="line">PREFIX=16 #该属性要与netmask正确组合，否则会出现网卡不能使用的问题！！直接使用netmask最好</span><br><span class="line">GATEWAY=192.168.1.1</span><br><span class="line">DNS1=1.1.1.1 #dns设置，可以多设置几个</span><br><span class="line">DEFROUTE=yes</span><br><span class="line">IPV4_FAILURE_FATAL=yes</span><br><span class="line">IPV6INIT=no</span><br><span class="line">NAME=&quot;System eth0&quot;</span><br><span class="line">HWADDR=FE:B8:DE:D1:DA:D0</span><br></pre></td></tr></table></figure><p></p><h2 id="1-4-复制多个虚拟机"><a href="#1-4-复制多个虚拟机" class="headerlink" title="1.4 复制多个虚拟机"></a>1.4 复制多个虚拟机</h2><h3 id="1-4-1-复制"><a href="#1-4-1-复制" class="headerlink" title="1.4.1 复制"></a>1.4.1 复制</h3><p>XenCenter支持快速复制多个虚拟机，选择合适的模式即可。</p><p><img src="\images\pasted-24.png" alt="upload successful"></p><blockquote><p>可以通过复制（兊隆）现有 VM 的方式创建新的 VM。 XenServer 使用完成复制和快速兊隆返两种机制<br>来复制 VM：<br>􀀀 完整复制生成 VM 磁盘的完整副本；<br>􀀀 快速兊隆（写入时复制）仅将修改的数据块写入磁盘，使用硬件级别的兊隆功能将现有 VM 中的磁盘<br>复制到新 VM。只有采用文件作为后端的 VM 才支持此模式。写入时复制旨在节省磁盘空间并实现快速兊<br>隆，但会略微减低正常的磁盘性能。<br>只能在同一个资源池中直接复制 VM。要将 VM 复制到其他池中的服务器，需要导出 VM，然后再将其导<br>入目标服务器。</p></blockquote><h3 id="1-4-2-配置"><a href="#1-4-2-配置" class="headerlink" title="1.4.2 配置"></a>1.4.2 配置</h3><p>复制完成后我们需要调整网卡和主机名<br></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/network</span><br><span class="line"><span class="meta">#</span>修改hostname值</span><br><span class="line"></span><br><span class="line">ifconfig eht0 #查看网卡mac地址</span><br><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-eth0</span><br><span class="line"><span class="meta">#</span>修改HWADDR的值为mac地址</span><br><span class="line">service network restart</span><br></pre></td></tr></table></figure><p></p><h1 id="2-执行ambari自动部署脚本（略）"><a href="#2-执行ambari自动部署脚本（略）" class="headerlink" title="2.执行ambari自动部署脚本（略）"></a>2.执行ambari自动部署脚本（略）</h1><p>这里大家可以自行寻找符合要求的自动化部署脚本。我们这里采用了离线部署的方式。简单列出思路</p><ol><li>在NameNode上搭建ftp服务器（或http都可）</li><li>将hortonworks的工具包拷入服务器目录</li><li>将centos的离线包环境拷入节点仓库，即替换repo</li><li>修改所有节点hosts</li><li>配置所有节点ssh免密</li><li>配置节点ntp同步</li><li>关闭selinux</li><li>关闭防火墙</li><li>关闭packagekit</li><li>统一安装jdk</li><li>安装ambari-server</li><li>设置开机自启动ftp、ntp、ambari服务</li></ol><h1 id="3-安装HDP"><a href="#3-安装HDP" class="headerlink" title="3.安装HDP"></a>3.安装HDP</h1><h2 id="3-1-配置Ambari"><a href="#3-1-配置Ambari" class="headerlink" title="3.1 配置Ambari"></a>3.1 配置Ambari</h2><p>在上一步执行了Ambari-server setup后，有些简单的配置，这里说一下<br><img src="\images\pasted-25.png" alt="upload successful"><br>若没重启，selinux很可能没关闭，这时选继续（y）会临时关闭，密码直接回车就好，默认账户，jdk选择自定义输入自己的路径即可。</p><p><img src="\images\pasted-26.png" alt="upload successful"><br>数据库这里我们用默认的postgresql，存储密码等信息，网上有使用mysql的。可自行查阅，</p><h2 id="3-2-开始安装HDP"><a href="#3-2-开始安装HDP" class="headerlink" title="3.2 开始安装HDP"></a>3.2 开始安装HDP</h2><p>选关键部分进行截图说明</p><ul><li>开始安装<br><img src="\images\pasted-28.png" alt="upload successful"></li><li>可用公有仓库，但需要将地址修改为自己的ftp地址，总之是使用离线地址，即server发布的地址，这也就是为什么用ftp和httpd服务的原因了，可跳过验证<br><img src="\images\pasted-29.png" alt="upload successful"></li><li>添加集群列表，导入主节点ambari-server的id_rsa，为了后面装ambri-agent用</li></ul><p><img src="\images\pasted-30.png" alt="upload successful"></p><ul><li>输入相关组件默认密码，根据提示输入默认密码即可</li></ul><p><img src="\\images\pasted-31.png\" alt="upload successful"></p><ul><li>若在deploy时提示什么url错误的，先使用ambari-server stop -&gt; ambari-server reset -&gt;ambari-server start 重置一下应该能解决，忘了截图<h2 id="3-3-可能出现的问题"><a href="#3-3-可能出现的问题" class="headerlink" title="3.3 可能出现的问题"></a>3.3 可能出现的问题</h2>安装过程中可能会出现很多问题，注意看提示进行解决，<strong>centos6.4-hdp1.x</strong>版本时没出现问题。<br>这里我列出几个自己在<strong>centos7-hdp2.5</strong>环境遇到的问题。</li><li>datanode安装失败，查看提示信息，发现是snappy版本过高<br><img src="\images\pasted-32.png" alt="upload successful"><br>卸载新版本snappy，安装指定版本snappy</li></ul><p><img src="\images\pasted-33.png" alt="upload successful"><br>指定版本在所需工具中有，我们有离线源可以安装。</p><p><img src="\images\pasted-34.png" alt="upload successful"></p><h1 id="4-补充-配置本地源"><a href="#4-补充-配置本地源" class="headerlink" title="4.(补充)配置本地源"></a>4.(补充)配置本地源</h1><p>这里对整个过程做一个总结，并总结一下配置本地源的过程。</p><h2 id="4-1-自动化部署的思路"><a href="#4-1-自动化部署的思路" class="headerlink" title="4.1 自动化部署的思路"></a>4.1 自动化部署的思路</h2><p>总的来说就是在离线环境下安装Ambari和HDP集群。ftp文件夹下除了Ambari和hdp安装包，还需要一个系统镜像包，这是为了执行脚本时安装一些工具方便，比如vsftp和expect等。</p><ul><li>开启ftp服务，为了使用yum进行相关软件安装，为了安完Ambari后离线安装hdp，可以在网上看到有人也采用httpd方式，功能一样</li><li>配置ssh免密登陆，这是方便后续配置的方式，可见Hadoop机群搭建</li><li>ntp机群时间同步：必须步骤</li><li>关闭SElinux和iptables：防止出现一些不必要的拦截，关闭不是最好的方式，却是最简单有效的方式。</li><li>关闭packagekit：防止更新出现一些不可知的问题。</li></ul><h2 id="4-2-配置本地环境"><a href="#4-2-配置本地环境" class="headerlink" title="4.2 配置本地环境"></a>4.2 配置本地环境</h2><p>主要就是ftp目录下的几个文件来源</p><h3 id="4-2-1-OS"><a href="#4-2-1-OS" class="headerlink" title="4.2.1 OS"></a>4.2.1 OS</h3><p>系统依赖就是iso镜像下的这两个文件夹。</p><p><img src="\images\pasted-35.png" alt="upload successful"></p><h3 id="4-2-2-Ambari及hdp"><a href="#4-2-2-Ambari及hdp" class="headerlink" title="4.2.2 Ambari及hdp"></a>4.2.2 Ambari及hdp</h3><p>去官网<a href="https://docs.hortonworks.com" target="_blank" rel="noopener">https://docs.hortonworks.com</a> 下载tar包，解压即可，总共三个部分<br><img src="\images\pasted-36.png" alt="upload successful"><br><img src="\images\pasted-37.png" alt="upload successful"><br><img src="\images\pasted-38.png" alt="upload successful"></p><h3 id="4-3-3-配置repo包路径"><a href="#4-3-3-配置repo包路径" class="headerlink" title="4.3.3 配置repo包路径"></a>4.3.3 配置repo包路径</h3><p>前面提到过，在NameNode下有repo包，包中指定的路径为ftp服务路径，将其中所有路径改为正确的路径即可。</p><p><img src="\images\pasted-39.png" alt="upload successful"></p><h1 id="5-确认"><a href="#5-确认" class="headerlink" title="5.确认"></a>5.确认</h1><p>最后<strong>重启</strong>确保所有节点的<strong>时间同步，jdk一致，防火墙、selinux关闭、开机自启正常</strong>。</p><h1 id="6-踩坑记录"><a href="#6-踩坑记录" class="headerlink" title="6.踩坑记录"></a>6.踩坑记录</h1><h2 id="6-1-ssh不能登陆"><a href="#6-1-ssh不能登陆" class="headerlink" title="6.1 ssh不能登陆"></a>6.1 ssh不能登陆</h2><p>导致该问题的根源是，sshd守护进程不知怎么地不能加载SSH主机密钥了。<br>当OpenSSH服务器第一次安装到Linux系统时，SSH主机密钥应该会自动生成以供后续使用。如果，不管怎样，密钥生成过程没有成功完成，那就会导致这样的SSH登录问题。<br>若发现ssh不能登陆提示<strong>Read from socket failed: Connection reset by peer</strong><br>先去/var/log/messages下查看，若是发现类似提示<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Dec 15 19:44:56 localhost sshd[3136]: error: Could not load host key: /etc/ssh/ssh_host_ed25519_key</span><br><span class="line"></span><br><span class="line">Dec 15 19:47:03 localhost sshd[3138]: error: Could not load host key: /etc/ssh/ssh_host_ecdsa_key</span><br><span class="line"></span><br><span class="line">Dec 15 19:47:03 localhost sshd[3138]: error: Could not load host key: /etc/ssh/ssh_host_ed25519_key</span><br><span class="line"></span><br><span class="line">#看缺少那个key，用下面命令生成</span><br><span class="line">ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key</span><br><span class="line">ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key</span><br><span class="line">ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key</span><br><span class="line">ssh-keygen -t dsa -f /etc/ssh/ssh_host_ed25519_key</span><br></pre></td></tr></table></figure><p></p><h2 id="6-1用户问题"><a href="#6-1用户问题" class="headerlink" title="6.1用户问题"></a>6.1用户问题</h2><p>confirm hosts 步骤是默认使用root用户进行主机注册的。<br>如果使用脚本安装时不是root用户，即此时生成的ssh也不是root的，在ambari安装时记得先初始化设置用户为你使用的用户。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Mon Jun 03 2019 22:43:00 GMT+0800 (中国标准时间) --&gt;&lt;h2 id=&quot;一些旧文章，因为一些原因内容有删减，发出来鞭尸。&quot;&gt;&lt;a href=&quot;#一些旧文章，因为一些原因内容有删减，发出来鞭尸。&quot; class=&quot;h
      
    
    </summary>
    
      <category term="Hadoop集群搭建" scheme="http://yoursite.com/categories/Hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="Hadoop集群搭建" scheme="http://yoursite.com/tags/Hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>VMware中Ubuntu下配置Hadoop环境</title>
    <link href="http://yoursite.com/2019/06/03/VMware%E4%B8%ADUbuntu%E4%B8%8B%E9%85%8D%E7%BD%AEHadoop%E7%8E%AF%E5%A2%83/"/>
    <id>http://yoursite.com/2019/06/03/VMware中Ubuntu下配置Hadoop环境/</id>
    <published>2019-06-03T12:41:00.000Z</published>
    <updated>2019-06-03T13:52:05.299Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Jun 03 2019 21:52:17 GMT+0800 (中国标准时间) --><h2 id="最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。"><a href="#最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。" class="headerlink" title="最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。"></a>最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。</h2><h1 id="一、在虚拟机中安装Ubuntu"><a href="#一、在虚拟机中安装Ubuntu" class="headerlink" title="一、在虚拟机中安装Ubuntu"></a>一、在虚拟机中安装Ubuntu</h1><p>此处不再详述，虚拟机中安装Ubuntu较为简单。本人使用的版本是Ubuntu14.04。<br>注：最好安装vm提供的tools工具，控制起来较为方便。<br>这里说明一下vm中网络配置的问题：<br>为了能在windows下使用eclipse开发，所以需要设置虚拟机为“仅主机模式”。此模式可以使虚拟机与宿主机互通。</p><h2 id="1-vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192-168-1-0-完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192-168-1-2-255-255-255-0"><a href="#1-vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192-168-1-0-完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192-168-1-2-255-255-255-0" class="headerlink" title="1. vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192.168.1.0.完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192.168.1.2 255.255.255.0"></a>1. vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192.168.1.0.完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192.168.1.2 255.255.255.0</h2><p><img src="\images\pasted-0.png" alt="upload successful"><br><img src="\images\pasted-1.png" alt="upload successful"></p><h2 id="2-进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192-168-1-10）。或修改-etc-network-interfaces目录，在最后补充如下内容"><a href="#2-进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192-168-1-10）。或修改-etc-network-interfaces目录，在最后补充如下内容" class="headerlink" title="2.进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192.168.1.10）。或修改/etc/network/interfaces目录，在最后补充如下内容"></a>2.进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192.168.1.10）。或修改/etc/network/interfaces目录，在最后补充如下内容</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">auto ens33      #注意，由于使用的为Ubuntu16.04，默认不是eth0。如果不确定可用ifconfig命令进行查看</span><br><span class="line">iface ens33 inet static</span><br><span class="line">address 192.168.1.10</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">gateway 192.168.1.1</span><br><span class="line">broadcast 192.168.1.255</span><br></pre></td></tr></table></figure><p>ps： 【本方法不知为何个人操作失败，无法设定，待解决】</p><h2 id="3-可在宿主机运行cmd，在控制台进行ping命令，若能ping通192-168-1-10，则配置完成。"><a href="#3-可在宿主机运行cmd，在控制台进行ping命令，若能ping通192-168-1-10，则配置完成。" class="headerlink" title="3.可在宿主机运行cmd，在控制台进行ping命令，若能ping通192.168.1.10，则配置完成。"></a>3.可在宿主机运行cmd，在控制台进行ping命令，若能ping通192.168.1.10，则配置完成。</h2><p>补充【以下可在安装完hadoop后再进行】：</p><h2 id="4-对第一台虚拟机进行重命名，文件在-etc-hostname下，本次设定为Master。之后需要在-etc-hosts文件中将127-0-0-1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。"><a href="#4-对第一台虚拟机进行重命名，文件在-etc-hostname下，本次设定为Master。之后需要在-etc-hosts文件中将127-0-0-1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。" class="headerlink" title="4.对第一台虚拟机进行重命名，文件在/etc/hostname下，本次设定为Master。之后需要在/etc/hosts文件中将127.0.0.1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。"></a>4.对第一台虚拟机进行重命名，文件在/etc/hostname下，本次设定为Master。之后需要在/etc/hosts文件中将127.0.0.1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。</h2><h2 id="5-在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192-168-1-20），并进行重命名（slave1）。"><a href="#5-在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192-168-1-20），并进行重命名（slave1）。" class="headerlink" title="5.在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192.168.1.20），并进行重命名（slave1）。"></a>5.在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192.168.1.20），并进行重命名（slave1）。</h2><h2 id="6-指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。"><a href="#6-指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。" class="headerlink" title="6.指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。"></a>6.指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。</h2><h1 id="二、配置Java开发环境（安装JDK）"><a href="#二、配置Java开发环境（安装JDK）" class="headerlink" title="二、配置Java开发环境（安装JDK）"></a>二、配置Java开发环境（安装JDK）</h1><p>本次所用JDK安装包为jdk-8u5-linux-x64.tar.gz，可选择合适版本进行安装。<br>说明：<br>1）linux在启动过程中，会先执行/etc/profile文件，然后执行用户目录下的~/.bash_profile、~/bash_login、~/.profile中的其中一个（执行优先级为从左到右）。如果~/.bash_profile文件存在的话，一般还会执行~/.bashrc。/etc/profile是全局配置文件，适用于所有用户，其他用户目录的配置文件只适用于某个用户，对其他用户就不起作用了。本文中配置的位置为/etc/profile，即为所有用户配置JDK环境。<br>2）安装过程中所有需要使用sudo命令的地方均不可少，图形化界面权限不够。</p><h2 id="1-一般从网上下载会放在‘下载’位置下，我将它放在桌面上。"><a href="#1-一般从网上下载会放在‘下载’位置下，我将它放在桌面上。" class="headerlink" title="1.一般从网上下载会放在‘下载’位置下，我将它放在桌面上。"></a>1.一般从网上下载会放在‘下载’位置下，我将它放在桌面上。</h2><p>进入安装包所在目录，执行下图命令 tar -zxvf：</p><p><img src="\images\pasted-2.png" alt="upload successful"><br>将安装包解压至当前目录下。</p><h2 id="2-使用命令cd-usr-lib，进入lib目录下，执行sudo-mkdir-jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。"><a href="#2-使用命令cd-usr-lib，进入lib目录下，执行sudo-mkdir-jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。" class="headerlink" title="2.使用命令cd /usr/lib，进入lib目录下，执行sudo mkdir jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。"></a>2.使用命令cd /usr/lib，进入lib目录下，执行sudo mkdir jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。</h2><h2 id="3-回到先前解压安装包所在的目录，执行-sudo-mv命令，将解压文件夹移至jvm文件夹。如图"><a href="#3-回到先前解压安装包所在的目录，执行-sudo-mv命令，将解压文件夹移至jvm文件夹。如图" class="headerlink" title="3.回到先前解压安装包所在的目录，执行 sudo mv命令，将解压文件夹移至jvm文件夹。如图"></a>3.回到先前解压安装包所在的目录，执行 sudo mv命令，将解压文件夹移至jvm文件夹。如图</h2><p><img src="\images\pasted-3.png" alt="upload successful"></p><h2 id="4-执行sudo-gedit-etc-profile，进入profile文件，添加如下内容至文件尾"><a href="#4-执行sudo-gedit-etc-profile，进入profile文件，添加如下内容至文件尾" class="headerlink" title="4.执行sudo gedit etc/profile，进入profile文件，添加如下内容至文件尾"></a>4.执行sudo gedit etc/profile，进入profile文件，添加如下内容至文件尾</h2><p><img src="\\images\pasted-4.png\" alt="upload successful"><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_05   </span><br><span class="line">export JRE_HOME=$&#123;JAVA_HOME&#125;/jre    </span><br><span class="line">export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib    </span><br><span class="line">export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH</span><br></pre></td></tr></table></figure><p></p><h2 id="5-为了使配置直接生效，执行下图命令："><a href="#5-为了使配置直接生效，执行下图命令：" class="headerlink" title="5.为了使配置直接生效，执行下图命令："></a>5.为了使配置直接生效，执行下图命令：</h2><p><img src="\images\pasted-5.png" alt="upload successful"><br>这里如果不执行该命令，需要注销或重启，再次登陆后才能正确显示安装结果。</p><h2 id="6-验证JDK是否安装成功，执行java-version："><a href="#6-验证JDK是否安装成功，执行java-version：" class="headerlink" title="6.验证JDK是否安装成功，执行java -version："></a>6.验证JDK是否安装成功，执行java -version：</h2><p><img src="\images\pasted-6.png" alt="upload successful"><br>如果显示如图，则证明安装成功。</p><h1 id="三、新建hadoop用户并启用ssh免密登录"><a href="#三、新建hadoop用户并启用ssh免密登录" class="headerlink" title="三、新建hadoop用户并启用ssh免密登录"></a>三、新建hadoop用户并启用ssh免密登录</h1><p>这里我使用的是hadoop-2.6.0。</p><h2 id="1-新建hadoop用户，使用-bin-bash-作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。"><a href="#1-新建hadoop用户，使用-bin-bash-作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。" class="headerlink" title="1.新建hadoop用户，使用/bin/bash 作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。"></a>1.新建hadoop用户，使用/bin/bash 作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。</h2><p><img src="\images\pasted-7.png" alt="upload successful"></p><h2 id="2-安装并配置ssh"><a href="#2-安装并配置ssh" class="headerlink" title="2.安装并配置ssh"></a>2.安装并配置ssh</h2><p>1).Ubuntu默认安装了ssh client，但还需要安装ssh server，否则不能登录localhost，如下</p><p><img src="\images\pasted-8.png" alt="upload successful"><br>2).执行下图命令，安装ssh server，</p><p><img src="\images\pasted-9.png" alt="upload successful"><br>安装成功后可以登录localhost，不过需要输入密码，如下</p><p><img src="\images\pasted-10.png" alt="upload successful"><br>使用exit命令退出登录。<br>3).执行ssh-keygen命令，生成密钥对，再进入.ssh目录，将新生成的公钥复制到已授权秘钥列表，如下</p><p><img src="\images\pasted-11.png" alt="upload successful"><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp .ssh/id_rsa.pub .ssh/authorized_keys</span><br></pre></td></tr></table></figure><p></p><p>此时再尝试登录会发现已经不用再输入密码了，配置完成。</p><p><img src="\images\pasted-12.png" alt="upload successful"></p><p>补充：</p><h3 id="1-这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在-ssh目录中。"><a href="#1-这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在-ssh目录中。" class="headerlink" title="1.这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在.ssh目录中。"></a>1.这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在.ssh目录中。</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#若不采用虚拟机克隆，则需在slave中建立.ssh目录，在slave中执行如下命令</span><br><span class="line">hadoop@slave1：~$ mkdir .ssh</span><br><span class="line"></span><br><span class="line">#在master中执行以下命令，复制认证文件（这里的认证文件已经添加过本机的公钥了）</span><br><span class="line">hadoop@master:~./ssh$ scp authorized_keys hadoop@ slave1:/home/hadoop/.ssh</span><br></pre></td></tr></table></figure><p>这样一来可以直接使用ssh slave1来无秘登录对方。</p><h3 id="2-配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录"><a href="#2-配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录" class="headerlink" title="2.配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录"></a>2.配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录</h3><p>#以下修改在master上，建议先备份sshd_config<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/ssh</span><br><span class="line">sudo cp sshd_config sshd_config.bak</span><br><span class="line">sudo nano sshd_config</span><br><span class="line">#将下列三句改为no，并将第三句注释去掉。</span><br><span class="line">PermitRootLogin yes</span><br><span class="line">UsePAM yes</span><br><span class="line">#PasswordAuthentication yes</span><br></pre></td></tr></table></figure><p></p><h2 id="3-仅允许一台或一些机器登录ssh服务器"><a href="#3-仅允许一台或一些机器登录ssh服务器" class="headerlink" title="3.仅允许一台或一些机器登录ssh服务器"></a>3.仅允许一台或一些机器登录ssh服务器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#仍在sshd_config中编辑，加入如下语句即可</span><br><span class="line">allowusers hadoop@192.168.1.2</span><br><span class="line">#以上意思为仅允许192.168.1.2上的hadoop用户登录ssh，保证安全</span><br><span class="line">#重启服务</span><br><span class="line">service ssh restart</span><br></pre></td></tr></table></figure><h1 id="四、安装并配置Hadoop"><a href="#四、安装并配置Hadoop" class="headerlink" title="四、安装并配置Hadoop"></a>四、安装并配置Hadoop</h1><h2 id="4-1-解压安装hadoop"><a href="#4-1-解压安装hadoop" class="headerlink" title="4.1 解压安装hadoop"></a>4.1 解压安装hadoop</h2><p>1).这里和安装JDK类似，我将其装在/usr/local目录下的hadoop文件夹中，不再详述。<br>2).配置环境变量<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit /etc/profile</span><br><span class="line">#添加以下内容至文件尾</span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br></pre></td></tr></table></figure><p></p><p>找到hadoop-env.sh文件，将其中的”export JAVA_HOME=”一句填入Java的安装目录,此次所用版本该文件在/usr/local/hadoop/etc/hadoop目录下，根据版本找到该文件即可。<br>可使用hadoop version命令查看版本，若按照成功则会提示版本信息。<br>3).启动hadoop<br>启动文件为start-all.sh，2.6中在sbin目录下。<br>4).运行jps<br>可以查看有没有java进程在运行，正常状况下可以见到 xxx Jps 字样的提示。<br>5).结束hadoop<br>结束文件stop-all.sh。</p><h2 id="4-2配置伪分布模式"><a href="#4-2配置伪分布模式" class="headerlink" title="4.2配置伪分布模式"></a>4.2配置伪分布模式</h2><p>1).修改core-site.xml文件<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit ./etc/hadoop/core-site.xml</span><br><span class="line">#改为如下内容</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;</span><br><span class="line">             &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p></p><p>2).修改hdfs-site.xml文件<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit ./etc/hadoop/core-site.xml</span><br><span class="line">#改为如下内容</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p></p><p>（本段摘自网络）</p><blockquote><p>Hadoop配置文件说明<br>Hadoop 的运行方式是由配置文件决定的（运行 Hadoop 时会读取配置文件），因此如果需要从伪分布式模式切换回非分布式模式，需要删除 core-site.xml 中的配置项。此外，伪分布式虽然只需要配置 fs.defaultFS 和 dfs.replication 就可以运行（官方教程如此），不过若没有配置 hadoop.tmp.dir 参数，则默认使用的临时目录为 /tmp/hadoo-hadoop，而这个目录在重启时有可能被系统清理掉，导致必须重新执行 format 才行。所以我们进行了设置，同时也指定 dfs.namenode.name.dir 和 dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。</p></blockquote><p>3).格式化<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode -format</span><br></pre></td></tr></table></figure><p></p><p>4).启动hadoop（略）<br>5).运行Jps查看，若开启成功，则有如下提示</p><p><img src="\images\pasted-13.png" alt="upload successful"><br>6).关闭hadoop（略）</p><h1 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h1><p>安装过程中遇到了很多问题，通过网络及书籍等参考解决了大部分问题，水平有限，若有其他问题请联系我。<br>本次安装后对几个问题的理解：</p><h1 id="1-hadoop用户是必须建立的吗？"><a href="#1-hadoop用户是必须建立的吗？" class="headerlink" title="1.hadoop用户是必须建立的吗？"></a>1.hadoop用户是必须建立的吗？</h1><p>其实是非必要的，但是建议做。直接在默认用户上按照上述内容进行操作（省去建立用户即可），也可以完成配置。这里建议做的原因有两个：其一是为了方便配置，如果在默认用户上进行安装，有些文件夹（比如hadoop）的所有权在root上，会影响后续的格式化过程，可以修改文件夹权限来解决；其二是本着专用的原则，所有处理Hadoop的内容均在hadoop用户上进行，别的系统不会影响到本系统，反之亦然。</p><h1 id="2-关于SSH配置的用途"><a href="#2-关于SSH配置的用途" class="headerlink" title="2.关于SSH配置的用途"></a>2.关于SSH配置的用途</h1><p>最近本人在折腾路由器，用到了不少远程管理工具（putty，winSCP，SecureCRT），但路由器端必须开启ssh或talnet等。这里hadoop集群中主机也需要远程登录其他机器，来进行相关操作，因此必须配置相关内容，并且也能方便后续管理。</p><p>参考资料：</p><ol><li><p><a href="http://www.powerxing.com/install-hadoop/" target="_blank" rel="noopener">http://www.powerxing.com/install-hadoop/</a></p></li><li><p>《实战Hadoop大数据处理》，曾刚</p></li><li><p>《Hadoop基础教程》，Garry Turkington</p></li></ol><p>以上2016年11月28日 星期一 22:19:50</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Mon Jun 03 2019 21:52:17 GMT+0800 (中国标准时间) --&gt;&lt;h2 id=&quot;最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。&quot;&gt;&lt;a href=&quot;#最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。&quot; clas
      
    
    </summary>
    
      <category term="Hadoop环境搭建" scheme="http://yoursite.com/categories/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="Hadoop环境搭建" scheme="http://yoursite.com/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>常用git命令记录</title>
    <link href="http://yoursite.com/2019/03/03/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95/"/>
    <id>http://yoursite.com/2019/03/03/常用git命令记录/</id>
    <published>2019-03-03T13:30:00.000Z</published>
    <updated>2019-03-03T13:39:33.800Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 03 2019 21:39:34 GMT+0800 (中国标准时间) --><h1 id="1-远程仓库相关命令"><a href="#1-远程仓库相关命令" class="headerlink" title="1.远程仓库相关命令"></a>1.远程仓库相关命令</h1><p>检出仓库：$ git clone <a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>:co1de/co1de.github.io.git<br>查看远程仓库：$ git remote -v<br>添加远程仓库：$ git remote add [name] [url]<br>删除远程仓库：$ git remote rm [name]<br>修改远程仓库：$ git remote set-url –push[name][newUrl]<br>拉取远程仓库：$ git pull [remoteName] [localBranchName]<br>推送远程仓库：$ git push [remoteName] [localBranchName]</p><h1 id="2-分支-branch-操作相关命令"><a href="#2-分支-branch-操作相关命令" class="headerlink" title="2.分支(branch)操作相关命令"></a>2.分支(branch)操作相关命令</h1><p>查看本地分支：$ git branch<br>查看远程分支：$ git branch -r<br>创建本地分支：$ git branch [name] —-注意新分支创建后不会自动切换为当前分支<br>切换分支：$ git checkout [name]<br>创建新分支并立即切换到新分支：$ git checkout -b [name]<br>删除分支：$ git branch -d [name] —- -d选项只能删除已经参与了合并的分支，对于未有合并的分支是无法删除的。如果想强制删除一个分支，可以使用-D选项<br>合并分支：$ git merge [name] —-将名称为[name]的分支与当前分支合并<br>创建远程分支(本地分支push到远程)：$ git push origin [name]<br>删除远程分支：$ git push origin :heads/[name] 推送一个空分支，或是git push orgin –delete</p><p>记录一下常见的命令，方便查阅。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 03 2019 21:39:34 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;1-远程仓库相关命令&quot;&gt;&lt;a href=&quot;#1-远程仓库相关命令&quot; class=&quot;headerlink&quot; title=&quot;1.远程仓库相关命令
      
    
    </summary>
    
    
      <category term="git" scheme="http://yoursite.com/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>博客搭建相关（个人草稿）</title>
    <link href="http://yoursite.com/2019/02/20/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E7%9B%B8%E5%85%B3/"/>
    <id>http://yoursite.com/2019/02/20/博客搭建相关/</id>
    <published>2019-02-20T12:14:00.000Z</published>
    <updated>2019-03-03T15:34:38.694Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 03 2019 23:34:38 GMT+0800 (中国标准时间) --><p>本部分简略的记录了博客搭建过程中参考的主要网站</p><ul><li><a href="https://www.imooc.com/article/31085" target="_blank" rel="noopener">关于Hexo6.0搭建个人博客(github+Google-收录篇)</a> 里面连接的几篇文章读下来hexo应该就没问题了，这篇是用来部署的</li><li><a href="https://www.zhihu.com/question/21193762" target="_blank" rel="noopener">使用hexo，如果换了电脑怎么更新博客？ </a>博客迁移相关，主要是github分支和云盘两种方式。最终个人采用了云盘的方式（因为懒。。。）</li><li><a href="https://www.jianshu.com/p/c311d31265e0" target="_blank" rel="noopener">hexo页脚添加访客人数和总访问量</a>,利用busuanzi统计访问量，这是个hexo自带的，启用功能即可。这里必须要多说一点，total等属性是新版本的内容，启用的话会在下面显示小人像和眼睛图标，但如果在footer.swig中谢了span代码引用，代码那里会正常显示，而图标这里也有，但不会有计数了。还有site等属性好像是旧版本的，我单独设置了没起作用。最后我采用了代码引入的方式，可以定制样子。我用busuanzi是来统计访uv和pv的，文章相关内容交给了leancloud来统计。</li><li><a href="https://yfzhou.coding.me/2018/08/08/Hexo-Next%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%EF%BC%88%E6%B7%BB%E5%8A%A0%E7%BB%9F%E8%AE%A1%E8%AE%BF%E5%AE%A2%E9%87%8F%E4%BB%A5%E5%8F%8A%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%E9%87%8F%EF%BC%89/" target="_blank" rel="noopener">Hexo-Next搭建个人博客（添加统计访客量以及文章阅读量）</a>这里详细讲了leancloud的方式，也很简单。leancloud还能添加valine评论系统，next支持，简单好用。</li><li>除了压缩文件的方式，还是可以试一下在next的主题配置里关闭font，好像能快一点？？</li><li><a href="https://github.com/jaredly/hexo-admin/issues/70" target="_blank" rel="noopener">如何利用hexo admin直接发布</a></li></ul><p>hexo这东西折腾起来可以玩几天，有精力了再优化界面吧，只要博客写博客功能正常就行。<br>关于迁移的问题，我个人云盘备份，在新机器上直接npm install就完事了。<br>另外本人最后写博客用的是hexo admin方式，暂时能满足需要，不过有些语法好像支持有点问题，后面有时间继续折腾吧。<br>最后吐槽，访问实在是太慢了。。。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 03 2019 23:34:38 GMT+0800 (中国标准时间) --&gt;&lt;p&gt;本部分简略的记录了博客搭建过程中参考的主要网站&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.imooc.com/article/3
      
    
    </summary>
    
      <category term="博客搭建" scheme="http://yoursite.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
  </entry>
  
  <entry>
    <title>博客功能测试</title>
    <link href="http://yoursite.com/2019/01/27/hello-world/"/>
    <id>http://yoursite.com/2019/01/27/hello-world/</id>
    <published>2019-01-27T08:30:00.000Z</published>
    <updated>2019-02-20T12:27:07.562Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 03 2019 21:29:54 GMT+0800 (中国标准时间) --><h1 id="1-字数统计"><a href="#1-字数统计" class="headerlink" title="1.字数统计"></a>1.字数统计</h1><h1 id="1-1-这里是字数统计测试"><a href="#1-1-这里是字数统计测试" class="headerlink" title="1.1 这里是字数统计测试"></a>1.1 这里是字数统计测试</h1><p>压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 03 2019 21:29:54 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;1-字数统计&quot;&gt;&lt;a href=&quot;#1-字数统计&quot; class=&quot;headerlink&quot; title=&quot;1.字数统计&quot;&gt;&lt;/a&gt;1.字数统计
      
    
    </summary>
    
      <category term="博客搭建" scheme="http://yoursite.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
  </entry>
  
</feed>
