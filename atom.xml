<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>co1de&#39;s blogs</title>
  
  <subtitle>记录个人工作生活</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-06-03T13:18:47.387Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>co1de</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>VMware中Ubuntu下配置Hadoop环境</title>
    <link href="http://yoursite.com/2019/06/03/VMware%E4%B8%ADUbuntu%E4%B8%8B%E9%85%8D%E7%BD%AEHadoop%E7%8E%AF%E5%A2%83/"/>
    <id>http://yoursite.com/2019/06/03/VMware中Ubuntu下配置Hadoop环境/</id>
    <published>2019-06-03T12:41:00.000Z</published>
    <updated>2019-06-03T13:18:47.387Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Jun 03 2019 21:22:49 GMT+0800 (中国标准时间) --><h2 id="最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。"><a href="#最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。" class="headerlink" title="最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。"></a>最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。</h2><h1 id="一、在虚拟机中安装Ubuntu"><a href="#一、在虚拟机中安装Ubuntu" class="headerlink" title="一、在虚拟机中安装Ubuntu"></a>一、在虚拟机中安装Ubuntu</h1><p>此处不再详述，虚拟机中安装Ubuntu较为简单。本人使用的版本是Ubuntu14.04。<br>注：最好安装vm提供的tools工具，控制起来较为方便。<br>这里说明一下vm中网络配置的问题：<br>为了能在windows下使用eclipse开发，所以需要设置虚拟机为“仅主机模式”。此模式可以使虚拟机与宿主机互通。</p><h2 id="1-vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192-168-1-0-完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192-168-1-2-255-255-255-0"><a href="#1-vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192-168-1-0-完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192-168-1-2-255-255-255-0" class="headerlink" title="1. vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192.168.1.0.完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192.168.1.2 255.255.255.0"></a>1. vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192.168.1.0.完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192.168.1.2 255.255.255.0</h2><p><img src="\images\pasted-0.png" alt="upload successful"><br><img src="\images\pasted-1.png" alt="upload successful"></p><h2 id="2-进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192-168-1-10）。或修改-etc-network-interfaces目录，在最后补充如下内容"><a href="#2-进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192-168-1-10）。或修改-etc-network-interfaces目录，在最后补充如下内容" class="headerlink" title="2.进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192.168.1.10）。或修改/etc/network/interfaces目录，在最后补充如下内容"></a>2.进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192.168.1.10）。或修改/etc/network/interfaces目录，在最后补充如下内容</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">auto ens33      #注意，由于使用的为Ubuntu16.04，默认不是eth0。如果不确定可用ifconfig命令进行查看</span><br><span class="line">iface ens33 inet static</span><br><span class="line">address 192.168.1.10</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">gateway 192.168.1.1</span><br><span class="line">broadcast 192.168.1.255</span><br></pre></td></tr></table></figure><p>ps： 【本方法不知为何个人操作失败，无法设定，待解决】</p><h2 id="3-可在宿主机运行cmd，在控制台进行ping命令，若能ping通192-168-1-10，则配置完成。"><a href="#3-可在宿主机运行cmd，在控制台进行ping命令，若能ping通192-168-1-10，则配置完成。" class="headerlink" title="3.可在宿主机运行cmd，在控制台进行ping命令，若能ping通192.168.1.10，则配置完成。"></a>3.可在宿主机运行cmd，在控制台进行ping命令，若能ping通192.168.1.10，则配置完成。</h2><p>补充【以下可在安装完hadoop后再进行】：</p><h2 id="4-对第一台虚拟机进行重命名，文件在-etc-hostname下，本次设定为Master。之后需要在-etc-hosts文件中将127-0-0-1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。"><a href="#4-对第一台虚拟机进行重命名，文件在-etc-hostname下，本次设定为Master。之后需要在-etc-hosts文件中将127-0-0-1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。" class="headerlink" title="4.对第一台虚拟机进行重命名，文件在/etc/hostname下，本次设定为Master。之后需要在/etc/hosts文件中将127.0.0.1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。"></a>4.对第一台虚拟机进行重命名，文件在/etc/hostname下，本次设定为Master。之后需要在/etc/hosts文件中将127.0.0.1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。</h2><h2 id="5-在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192-168-1-20），并进行重命名（slave1）。"><a href="#5-在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192-168-1-20），并进行重命名（slave1）。" class="headerlink" title="5.在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192.168.1.20），并进行重命名（slave1）。"></a>5.在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192.168.1.20），并进行重命名（slave1）。</h2><h2 id="6-指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。"><a href="#6-指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。" class="headerlink" title="6.指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。"></a>6.指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。</h2><h1 id="二、配置Java开发环境（安装JDK）"><a href="#二、配置Java开发环境（安装JDK）" class="headerlink" title="二、配置Java开发环境（安装JDK）"></a>二、配置Java开发环境（安装JDK）</h1><p>本次所用JDK安装包为jdk-8u5-linux-x64.tar.gz，可选择合适版本进行安装。<br>说明：<br>1）linux在启动过程中，会先执行/etc/profile文件，然后执行用户目录下的~/.bash_profile、~/bash_login、~/.profile中的其中一个（执行优先级为从左到右）。如果~/.bash_profile文件存在的话，一般还会执行~/.bashrc。/etc/profile是全局配置文件，适用于所有用户，其他用户目录的配置文件只适用于某个用户，对其他用户就不起作用了。本文中配置的位置为/etc/profile，即为所有用户配置JDK环境。<br>2）安装过程中所有需要使用sudo命令的地方均不可少，图形化界面权限不够。</p><h2 id="1-一般从网上下载会放在‘下载’位置下，我将它放在桌面上。"><a href="#1-一般从网上下载会放在‘下载’位置下，我将它放在桌面上。" class="headerlink" title="1.一般从网上下载会放在‘下载’位置下，我将它放在桌面上。"></a>1.一般从网上下载会放在‘下载’位置下，我将它放在桌面上。</h2><p>进入安装包所在目录，执行下图命令 tar -zxvf：</p><p><img src="\images\pasted-2.png" alt="upload successful"><br>将安装包解压至当前目录下。</p><h2 id="2-使用命令cd-usr-lib，进入lib目录下，执行sudo-mkdir-jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。"><a href="#2-使用命令cd-usr-lib，进入lib目录下，执行sudo-mkdir-jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。" class="headerlink" title="2.使用命令cd /usr/lib，进入lib目录下，执行sudo mkdir jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。"></a>2.使用命令cd /usr/lib，进入lib目录下，执行sudo mkdir jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。</h2><h2 id="3-回到先前解压安装包所在的目录，执行-sudo-mv命令，将解压文件夹移至jvm文件夹。如图"><a href="#3-回到先前解压安装包所在的目录，执行-sudo-mv命令，将解压文件夹移至jvm文件夹。如图" class="headerlink" title="3.回到先前解压安装包所在的目录，执行 sudo mv命令，将解压文件夹移至jvm文件夹。如图"></a>3.回到先前解压安装包所在的目录，执行 sudo mv命令，将解压文件夹移至jvm文件夹。如图</h2><p><img src="\images\pasted-3.png" alt="upload successful"></p><h2 id="4-执行sudo-gedit-etc-profile，进入profile文件，添加如下内容至文件尾"><a href="#4-执行sudo-gedit-etc-profile，进入profile文件，添加如下内容至文件尾" class="headerlink" title="4.执行sudo gedit etc/profile，进入profile文件，添加如下内容至文件尾"></a>4.执行sudo gedit etc/profile，进入profile文件，添加如下内容至文件尾</h2><p><img src="\images\pasted-4.png" alt="upload successful"><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_05   </span><br><span class="line">export JRE_HOME=$&#123;JAVA_HOME&#125;/jre    </span><br><span class="line">export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib    </span><br><span class="line">export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH</span><br></pre></td></tr></table></figure><p></p><h2 id="5-为了使配置直接生效，执行下图命令："><a href="#5-为了使配置直接生效，执行下图命令：" class="headerlink" title="5.为了使配置直接生效，执行下图命令："></a>5.为了使配置直接生效，执行下图命令：</h2><p><img src="\images\pasted-5.png" alt="upload successful"><br>这里如果不执行该命令，需要注销或重启，再次登陆后才能正确显示安装结果。</p><h2 id="6-验证JDK是否安装成功，执行java-version："><a href="#6-验证JDK是否安装成功，执行java-version：" class="headerlink" title="6.验证JDK是否安装成功，执行java -version："></a>6.验证JDK是否安装成功，执行java -version：</h2><p><img src="\images\pasted-6.png" alt="upload successful"><br>如果显示如图，则证明安装成功。</p><h1 id="三、新建hadoop用户并启用ssh免密登录"><a href="#三、新建hadoop用户并启用ssh免密登录" class="headerlink" title="三、新建hadoop用户并启用ssh免密登录"></a>三、新建hadoop用户并启用ssh免密登录</h1><p>这里我使用的是hadoop-2.6.0。</p><h2 id="1-新建hadoop用户，使用-bin-bash-作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。"><a href="#1-新建hadoop用户，使用-bin-bash-作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。" class="headerlink" title="1.新建hadoop用户，使用/bin/bash 作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。"></a>1.新建hadoop用户，使用/bin/bash 作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。</h2><p><img src="\images\pasted-7.png" alt="upload successful"></p><h2 id="2-安装并配置ssh"><a href="#2-安装并配置ssh" class="headerlink" title="2.安装并配置ssh"></a>2.安装并配置ssh</h2><p>1).Ubuntu默认安装了ssh client，但还需要安装ssh server，否则不能登录localhost，如下</p><p><img src="\images\pasted-8.png" alt="upload successful"><br>2).执行下图命令，安装ssh server，</p><p><img src="\images\pasted-9.png" alt="upload successful"><br>安装成功后可以登录localhost，不过需要输入密码，如下<br><img src="index_files/14182000.png" alt=""><br>使用exit命令退出登录。<br>3).执行ssh-keygen命令，生成密钥对，再进入.ssh目录，将新生成的公钥复制到已授权秘钥列表，如下</p><p><img src="\images\pasted-10.png" alt="upload successful"><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp .ssh/id_rsa.pub .ssh/authorized_keys</span><br></pre></td></tr></table></figure><p></p><p>此时再尝试登录会发现已经不用再输入密码了，配置完成。</p><p><img src="\images\pasted-11.png" alt="upload successful"></p><p>补充：</p><h3 id="1-这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在-ssh目录中。"><a href="#1-这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在-ssh目录中。" class="headerlink" title="1.这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在.ssh目录中。"></a>1.这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在.ssh目录中。</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#若不采用虚拟机克隆，则需在slave中建立.ssh目录，在slave中执行如下命令</span><br><span class="line">hadoop@slave1：~$ mkdir .ssh</span><br><span class="line"></span><br><span class="line">#在master中执行以下命令，复制认证文件（这里的认证文件已经添加过本机的公钥了）</span><br><span class="line">hadoop@master:~./ssh$ scp authorized_keys hadoop@ slave1:/home/hadoop/.ssh</span><br></pre></td></tr></table></figure><p>这样一来可以直接使用ssh slave1来无秘登录对方。</p><h3 id="2-配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录"><a href="#2-配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录" class="headerlink" title="2.配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录"></a>2.配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录</h3><p>#以下修改在master上，建议先备份sshd_config<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/ssh</span><br><span class="line">sudo cp sshd_config sshd_config.bak</span><br><span class="line">sudo nano sshd_config</span><br><span class="line">#将下列三句改为no，并将第三句注释去掉。</span><br><span class="line">PermitRootLogin yes</span><br><span class="line">UsePAM yes</span><br><span class="line">#PasswordAuthentication yes</span><br></pre></td></tr></table></figure><p></p><h2 id="3-仅允许一台或一些机器登录ssh服务器"><a href="#3-仅允许一台或一些机器登录ssh服务器" class="headerlink" title="3.仅允许一台或一些机器登录ssh服务器"></a>3.仅允许一台或一些机器登录ssh服务器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#仍在sshd_config中编辑，加入如下语句即可</span><br><span class="line">allowusers hadoop@192.168.1.2</span><br><span class="line">#以上意思为仅允许192.168.1.2上的hadoop用户登录ssh，保证安全</span><br><span class="line">#重启服务</span><br><span class="line">service ssh restart</span><br></pre></td></tr></table></figure><h1 id="四、安装并配置Hadoop"><a href="#四、安装并配置Hadoop" class="headerlink" title="四、安装并配置Hadoop"></a>四、安装并配置Hadoop</h1><h2 id="4-1-解压安装hadoop"><a href="#4-1-解压安装hadoop" class="headerlink" title="4.1 解压安装hadoop"></a>4.1 解压安装hadoop</h2><p>1).这里和安装JDK类似，我将其装在/usr/local目录下的hadoop文件夹中，不再详述。<br>2).配置环境变量<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit /etc/profile</span><br><span class="line">#添加以下内容至文件尾</span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br></pre></td></tr></table></figure><p></p><p>找到hadoop-env.sh文件，将其中的”export JAVA_HOME=”一句填入Java的安装目录,此次所用版本该文件在/usr/local/hadoop/etc/hadoop目录下，根据版本找到该文件即可。<br>可使用hadoop version命令查看版本，若按照成功则会提示版本信息。<br>3).启动hadoop<br>启动文件为start-all.sh，2.6中在sbin目录下。<br>4).运行jps<br>可以查看有没有java进程在运行，正常状况下可以见到 xxx Jps 字样的提示。<br>5).结束hadoop<br>结束文件stop-all.sh。</p><h2 id="4-2配置伪分布模式"><a href="#4-2配置伪分布模式" class="headerlink" title="4.2配置伪分布模式"></a>4.2配置伪分布模式</h2><p>1).修改core-site.xml文件<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit ./etc/hadoop/core-site.xml</span><br><span class="line">#改为如下内容</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;</span><br><span class="line">             &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p></p><p>2).修改hdfs-site.xml文件<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit ./etc/hadoop/core-site.xml</span><br><span class="line">#改为如下内容</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p></p><p>（本段摘自网络）</p><blockquote><p>Hadoop配置文件说明<br>Hadoop 的运行方式是由配置文件决定的（运行 Hadoop 时会读取配置文件），因此如果需要从伪分布式模式切换回非分布式模式，需要删除 core-site.xml 中的配置项。此外，伪分布式虽然只需要配置 fs.defaultFS 和 dfs.replication 就可以运行（官方教程如此），不过若没有配置 hadoop.tmp.dir 参数，则默认使用的临时目录为 /tmp/hadoo-hadoop，而这个目录在重启时有可能被系统清理掉，导致必须重新执行 format 才行。所以我们进行了设置，同时也指定 dfs.namenode.name.dir 和 dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。</p></blockquote><p>3).格式化<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode -format</span><br></pre></td></tr></table></figure><p></p><p>4).启动hadoop（略）<br>5).运行Jps查看，若开启成功，则有如下提示</p><p><img src="\images\pasted-12.png" alt="upload successful"><br>6).关闭hadoop（略）</p><h1 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h1><p>安装过程中遇到了很多问题，通过网络及书籍等参考解决了大部分问题，水平有限，若有其他问题请联系我。<br>本次安装后对几个问题的理解：</p><h1 id="1-hadoop用户是必须建立的吗？"><a href="#1-hadoop用户是必须建立的吗？" class="headerlink" title="1.hadoop用户是必须建立的吗？"></a>1.hadoop用户是必须建立的吗？</h1><p>其实是非必要的，但是建议做。直接在默认用户上按照上述内容进行操作（省去建立用户即可），也可以完成配置。这里建议做的原因有两个：其一是为了方便配置，如果在默认用户上进行安装，有些文件夹（比如hadoop）的所有权在root上，会影响后续的格式化过程，可以修改文件夹权限来解决；其二是本着专用的原则，所有处理Hadoop的内容均在hadoop用户上进行，别的系统不会影响到本系统，反之亦然。</p><h1 id="2-关于SSH配置的用途"><a href="#2-关于SSH配置的用途" class="headerlink" title="2.关于SSH配置的用途"></a>2.关于SSH配置的用途</h1><p>最近本人在折腾路由器，用到了不少远程管理工具（putty，winSCP，SecureCRT），但路由器端必须开启ssh或talnet等。这里hadoop集群中主机也需要远程登录其他机器，来进行相关操作，因此必须配置相关内容，并且也能方便后续管理。</p><p>参考资料：</p><ol><li><p><a href="http://www.powerxing.com/install-hadoop/" target="_blank" rel="noopener">http://www.powerxing.com/install-hadoop/</a></p></li><li><p>《实战Hadoop大数据处理》，曾刚</p></li><li><p>《Hadoop基础教程》，Garry Turkington</p></li></ol><p>以上2016年11月28日 星期一 22:19:50</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Mon Jun 03 2019 21:22:49 GMT+0800 (中国标准时间) --&gt;&lt;h2 id=&quot;最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。&quot;&gt;&lt;a href=&quot;#最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。&quot; clas
      
    
    </summary>
    
    
      <category term="Hadoop环境搭建" scheme="http://yoursite.com/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>常用git命令记录</title>
    <link href="http://yoursite.com/2019/03/03/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95/"/>
    <id>http://yoursite.com/2019/03/03/常用git命令记录/</id>
    <published>2019-03-03T13:30:00.000Z</published>
    <updated>2019-03-03T13:39:33.800Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 03 2019 21:39:34 GMT+0800 (中国标准时间) --><h1 id="1-远程仓库相关命令"><a href="#1-远程仓库相关命令" class="headerlink" title="1.远程仓库相关命令"></a>1.远程仓库相关命令</h1><p>检出仓库：$ git clone <a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>:co1de/co1de.github.io.git<br>查看远程仓库：$ git remote -v<br>添加远程仓库：$ git remote add [name] [url]<br>删除远程仓库：$ git remote rm [name]<br>修改远程仓库：$ git remote set-url –push[name][newUrl]<br>拉取远程仓库：$ git pull [remoteName] [localBranchName]<br>推送远程仓库：$ git push [remoteName] [localBranchName]</p><h1 id="2-分支-branch-操作相关命令"><a href="#2-分支-branch-操作相关命令" class="headerlink" title="2.分支(branch)操作相关命令"></a>2.分支(branch)操作相关命令</h1><p>查看本地分支：$ git branch<br>查看远程分支：$ git branch -r<br>创建本地分支：$ git branch [name] —-注意新分支创建后不会自动切换为当前分支<br>切换分支：$ git checkout [name]<br>创建新分支并立即切换到新分支：$ git checkout -b [name]<br>删除分支：$ git branch -d [name] —- -d选项只能删除已经参与了合并的分支，对于未有合并的分支是无法删除的。如果想强制删除一个分支，可以使用-D选项<br>合并分支：$ git merge [name] —-将名称为[name]的分支与当前分支合并<br>创建远程分支(本地分支push到远程)：$ git push origin [name]<br>删除远程分支：$ git push origin :heads/[name] 推送一个空分支，或是git push orgin –delete</p><p>记录一下常见的命令，方便查阅。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 03 2019 21:39:34 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;1-远程仓库相关命令&quot;&gt;&lt;a href=&quot;#1-远程仓库相关命令&quot; class=&quot;headerlink&quot; title=&quot;1.远程仓库相关命令
      
    
    </summary>
    
    
      <category term="git" scheme="http://yoursite.com/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>博客搭建相关（个人草稿）</title>
    <link href="http://yoursite.com/2019/02/20/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E7%9B%B8%E5%85%B3/"/>
    <id>http://yoursite.com/2019/02/20/博客搭建相关/</id>
    <published>2019-02-20T12:14:00.000Z</published>
    <updated>2019-03-03T15:34:38.694Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 03 2019 23:34:38 GMT+0800 (中国标准时间) --><p>本部分简略的记录了博客搭建过程中参考的主要网站</p><ul><li><a href="https://www.imooc.com/article/31085" target="_blank" rel="noopener">关于Hexo6.0搭建个人博客(github+Google-收录篇)</a> 里面连接的几篇文章读下来hexo应该就没问题了，这篇是用来部署的</li><li><a href="https://www.zhihu.com/question/21193762" target="_blank" rel="noopener">使用hexo，如果换了电脑怎么更新博客？ </a>博客迁移相关，主要是github分支和云盘两种方式。最终个人采用了云盘的方式（因为懒。。。）</li><li><a href="https://www.jianshu.com/p/c311d31265e0" target="_blank" rel="noopener">hexo页脚添加访客人数和总访问量</a>,利用busuanzi统计访问量，这是个hexo自带的，启用功能即可。这里必须要多说一点，total等属性是新版本的内容，启用的话会在下面显示小人像和眼睛图标，但如果在footer.swig中谢了span代码引用，代码那里会正常显示，而图标这里也有，但不会有计数了。还有site等属性好像是旧版本的，我单独设置了没起作用。最后我采用了代码引入的方式，可以定制样子。我用busuanzi是来统计访uv和pv的，文章相关内容交给了leancloud来统计。</li><li><a href="https://yfzhou.coding.me/2018/08/08/Hexo-Next%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%EF%BC%88%E6%B7%BB%E5%8A%A0%E7%BB%9F%E8%AE%A1%E8%AE%BF%E5%AE%A2%E9%87%8F%E4%BB%A5%E5%8F%8A%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%E9%87%8F%EF%BC%89/" target="_blank" rel="noopener">Hexo-Next搭建个人博客（添加统计访客量以及文章阅读量）</a>这里详细讲了leancloud的方式，也很简单。leancloud还能添加valine评论系统，next支持，简单好用。</li><li>除了压缩文件的方式，还是可以试一下在next的主题配置里关闭font，好像能快一点？？</li><li><a href="https://github.com/jaredly/hexo-admin/issues/70" target="_blank" rel="noopener">如何利用hexo admin直接发布</a></li></ul><p>hexo这东西折腾起来可以玩几天，有精力了再优化界面吧，只要博客写博客功能正常就行。<br>关于迁移的问题，我个人云盘备份，在新机器上直接npm install就完事了。<br>另外本人最后写博客用的是hexo admin方式，暂时能满足需要，不过有些语法好像支持有点问题，后面有时间继续折腾吧。<br>最后吐槽，访问实在是太慢了。。。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 03 2019 23:34:38 GMT+0800 (中国标准时间) --&gt;&lt;p&gt;本部分简略的记录了博客搭建过程中参考的主要网站&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.imooc.com/article/3
      
    
    </summary>
    
      <category term="博客搭建" scheme="http://yoursite.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
  </entry>
  
  <entry>
    <title>博客功能测试</title>
    <link href="http://yoursite.com/2019/01/27/hello-world/"/>
    <id>http://yoursite.com/2019/01/27/hello-world/</id>
    <published>2019-01-27T08:30:00.000Z</published>
    <updated>2019-02-20T12:27:07.562Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 03 2019 21:29:54 GMT+0800 (中国标准时间) --><h1 id="1-字数统计"><a href="#1-字数统计" class="headerlink" title="1.字数统计"></a>1.字数统计</h1><h1 id="1-1-这里是字数统计测试"><a href="#1-1-这里是字数统计测试" class="headerlink" title="1.1 这里是字数统计测试"></a>1.1 这里是字数统计测试</h1><p>压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0压缩测试1.0</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 03 2019 21:29:54 GMT+0800 (中国标准时间) --&gt;&lt;h1 id=&quot;1-字数统计&quot;&gt;&lt;a href=&quot;#1-字数统计&quot; class=&quot;headerlink&quot; title=&quot;1.字数统计&quot;&gt;&lt;/a&gt;1.字数统计
      
    
    </summary>
    
      <category term="博客搭建" scheme="http://yoursite.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
  </entry>
  
</feed>
