<!-- build time:Mon Jun 03 2019 21:27:02 GMT+0800 (中国标准时间) --><!DOCTYPE html><html class="theme-next pisces use-motion" lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script><link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2"><link rel="stylesheet" href="/css/main.css?v=6.7.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.7.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/run32.png?v=6.7.0"><link rel="icon" type="image/png" sizes="16x16" href="/images/run16.png?v=6.7.0"><link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222"><script id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Pisces",version:"6.7.0",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!0,onmobile:!1},fancybox:!1,fastclick:!1,lazyload:!1,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。一、在虚拟机中安装Ubuntu此处不再详述，虚拟机中安装Ubuntu较为简单。本人使用的版本是Ubuntu14.04。注：最好安装vm提供的tools工具，控制起来较为方便。这里说明一下vm中网络配置的问题：为了能在windows下使用eclipse开发，所以需要设置虚拟机为“仅主机模式”。此模式可以使虚拟机与宿主机互通。1. vm中vmnet1"><meta name="keywords" content="Hadoop环境搭建"><meta property="og:type" content="article"><meta property="og:title" content="VMware中Ubuntu下配置Hadoop环境"><meta property="og:url" content="http://yoursite.com/2019/06/03/VMware中Ubuntu下配置Hadoop环境/index.html"><meta property="og:site_name" content="co1de&#39;s blogs"><meta property="og:description" content="最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。一、在虚拟机中安装Ubuntu此处不再详述，虚拟机中安装Ubuntu较为简单。本人使用的版本是Ubuntu14.04。注：最好安装vm提供的tools工具，控制起来较为方便。这里说明一下vm中网络配置的问题：为了能在windows下使用eclipse开发，所以需要设置虚拟机为“仅主机模式”。此模式可以使虚拟机与宿主机互通。1. vm中vmnet1"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="http://yoursite.com/images/pasted-0.png"><meta property="og:image" content="http://yoursite.com/images/pasted-1.png"><meta property="og:image" content="http://yoursite.com/images/pasted-2.png"><meta property="og:image" content="http://yoursite.com/images/pasted-3.png"><meta property="og:image" content="http://yoursite.com/images/pasted-4.png"><meta property="og:image" content="http://yoursite.com/images/pasted-5.png"><meta property="og:image" content="http://yoursite.com/images/pasted-6.png"><meta property="og:image" content="http://yoursite.com/images/pasted-7.png"><meta property="og:image" content="http://yoursite.com/images/pasted-8.png"><meta property="og:image" content="http://yoursite.com/images/pasted-9.png"><meta property="og:image" content="http://yoursite.com/2019/06/03/VMware中Ubuntu下配置Hadoop环境/index_files/14182000.png"><meta property="og:image" content="http://yoursite.com/images/pasted-10.png"><meta property="og:image" content="http://yoursite.com/images/pasted-11.png"><meta property="og:image" content="http://yoursite.com/images/pasted-12.png"><meta property="og:updated_time" content="2019-06-03T13:26:54.684Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="VMware中Ubuntu下配置Hadoop环境"><meta name="twitter:description" content="最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。一、在虚拟机中安装Ubuntu此处不再详述，虚拟机中安装Ubuntu较为简单。本人使用的版本是Ubuntu14.04。注：最好安装vm提供的tools工具，控制起来较为方便。这里说明一下vm中网络配置的问题：为了能在windows下使用eclipse开发，所以需要设置虚拟机为“仅主机模式”。此模式可以使虚拟机与宿主机互通。1. vm中vmnet1"><meta name="twitter:image" content="http://yoursite.com/images/pasted-0.png"><link rel="canonical" href="http://yoursite.com/2019/06/03/VMware中Ubuntu下配置Hadoop环境/"><script id="page.configurations">CONFIG.page={sidebar:""}</script><title>VMware中Ubuntu下配置Hadoop环境 | co1de's blogs</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><a href="https://github.com/co1de" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513;color:#fff;position:absolute;top:0;border:0;right:0" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">co1de's blogs</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">记录个人工作生活</p></div><div class="site-nav-toggle"><button aria-label="切换导航栏"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/03/VMware中Ubuntu下配置Hadoop环境/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="co1de"><meta itemprop="description" content="保持好奇心，提高行动力"><meta itemprop="image" content="/images/run.jpg"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="co1de's blogs"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">VMware中Ubuntu下配置Hadoop环境</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-06-03 20:41:00 / 修改时间：21:26:54" itemprop="dateCreated datePublished" datetime="2019-06-03T20:41:00+08:00">2019-06-03</time> </span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Hadoop环境搭建/" itemprop="url" rel="index"><span itemprop="name">Hadoop环境搭建</span></a></span> </span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2019/06/03/VMware中Ubuntu下配置Hadoop环境/#comments" itemprop="discussionUrl"><span class="post-meta-item-text">评论数：</span> <span class="post-comments-count valine-comment-count" data-xid="/2019/06/03/VMware中Ubuntu下配置Hadoop环境/" itemprop="commentCount"></span> </a></span><span id="/2019/06/03/VMware中Ubuntu下配置Hadoop环境/" class="leancloud_visitors" data-flag-title="VMware中Ubuntu下配置Hadoop环境"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> 次</span><div class="post-symbolscount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">本文字数：</span> <span title="本文字数">5.5k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">5 分钟</span></div></div></header><div class="post-body" itemprop="articleBody"><h2 id="最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。"><a href="#最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。" class="headerlink" title="最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。"></a>最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。</h2><h1 id="一、在虚拟机中安装Ubuntu"><a href="#一、在虚拟机中安装Ubuntu" class="headerlink" title="一、在虚拟机中安装Ubuntu"></a>一、在虚拟机中安装Ubuntu</h1><p>此处不再详述，虚拟机中安装Ubuntu较为简单。本人使用的版本是Ubuntu14.04。<br>注：最好安装vm提供的tools工具，控制起来较为方便。<br>这里说明一下vm中网络配置的问题：<br>为了能在windows下使用eclipse开发，所以需要设置虚拟机为“仅主机模式”。此模式可以使虚拟机与宿主机互通。</p><h2 id="1-vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192-168-1-0-完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192-168-1-2-255-255-255-0"><a href="#1-vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192-168-1-0-完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192-168-1-2-255-255-255-0" class="headerlink" title="1. vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192.168.1.0.完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192.168.1.2 255.255.255.0"></a>1. vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192.168.1.0.完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192.168.1.2 255.255.255.0</h2><p><img src="\images\pasted-0.png" alt="upload successful"><br><img src="\images\pasted-1.png" alt="upload successful"></p><h2 id="2-进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192-168-1-10）。或修改-etc-network-interfaces目录，在最后补充如下内容"><a href="#2-进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192-168-1-10）。或修改-etc-network-interfaces目录，在最后补充如下内容" class="headerlink" title="2.进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192.168.1.10）。或修改/etc/network/interfaces目录，在最后补充如下内容"></a>2.进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192.168.1.10）。或修改/etc/network/interfaces目录，在最后补充如下内容</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">auto ens33      #注意，由于使用的为Ubuntu16.04，默认不是eth0。如果不确定可用ifconfig命令进行查看</span><br><span class="line">iface ens33 inet static</span><br><span class="line">address 192.168.1.10</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">gateway 192.168.1.1</span><br><span class="line">broadcast 192.168.1.255</span><br></pre></td></tr></table></figure><p>ps： 【本方法不知为何个人操作失败，无法设定，待解决】</p><h2 id="3-可在宿主机运行cmd，在控制台进行ping命令，若能ping通192-168-1-10，则配置完成。"><a href="#3-可在宿主机运行cmd，在控制台进行ping命令，若能ping通192-168-1-10，则配置完成。" class="headerlink" title="3.可在宿主机运行cmd，在控制台进行ping命令，若能ping通192.168.1.10，则配置完成。"></a>3.可在宿主机运行cmd，在控制台进行ping命令，若能ping通192.168.1.10，则配置完成。</h2><p>补充【以下可在安装完hadoop后再进行】：</p><h2 id="4-对第一台虚拟机进行重命名，文件在-etc-hostname下，本次设定为Master。之后需要在-etc-hosts文件中将127-0-0-1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。"><a href="#4-对第一台虚拟机进行重命名，文件在-etc-hostname下，本次设定为Master。之后需要在-etc-hosts文件中将127-0-0-1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。" class="headerlink" title="4.对第一台虚拟机进行重命名，文件在/etc/hostname下，本次设定为Master。之后需要在/etc/hosts文件中将127.0.0.1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。"></a>4.对第一台虚拟机进行重命名，文件在/etc/hostname下，本次设定为Master。之后需要在/etc/hosts文件中将127.0.0.1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。</h2><h2 id="5-在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192-168-1-20），并进行重命名（slave1）。"><a href="#5-在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192-168-1-20），并进行重命名（slave1）。" class="headerlink" title="5.在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192.168.1.20），并进行重命名（slave1）。"></a>5.在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192.168.1.20），并进行重命名（slave1）。</h2><h2 id="6-指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。"><a href="#6-指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。" class="headerlink" title="6.指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。"></a>6.指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。</h2><h1 id="二、配置Java开发环境（安装JDK）"><a href="#二、配置Java开发环境（安装JDK）" class="headerlink" title="二、配置Java开发环境（安装JDK）"></a>二、配置Java开发环境（安装JDK）</h1><p>本次所用JDK安装包为jdk-8u5-linux-x64.tar.gz，可选择合适版本进行安装。<br>说明：<br>1）linux在启动过程中，会先执行/etc/profile文件，然后执行用户目录下的~/.bash_profile、~/bash_login、~/.profile中的其中一个（执行优先级为从左到右）。如果~/.bash_profile文件存在的话，一般还会执行~/.bashrc。/etc/profile是全局配置文件，适用于所有用户，其他用户目录的配置文件只适用于某个用户，对其他用户就不起作用了。本文中配置的位置为/etc/profile，即为所有用户配置JDK环境。<br>2）安装过程中所有需要使用sudo命令的地方均不可少，图形化界面权限不够。</p><h2 id="1-一般从网上下载会放在‘下载’位置下，我将它放在桌面上。"><a href="#1-一般从网上下载会放在‘下载’位置下，我将它放在桌面上。" class="headerlink" title="1.一般从网上下载会放在‘下载’位置下，我将它放在桌面上。"></a>1.一般从网上下载会放在‘下载’位置下，我将它放在桌面上。</h2><p>进入安装包所在目录，执行下图命令 tar -zxvf：</p><p><img src="\images\pasted-2.png" alt="upload successful"><br>将安装包解压至当前目录下。</p><h2 id="2-使用命令cd-usr-lib，进入lib目录下，执行sudo-mkdir-jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。"><a href="#2-使用命令cd-usr-lib，进入lib目录下，执行sudo-mkdir-jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。" class="headerlink" title="2.使用命令cd /usr/lib，进入lib目录下，执行sudo mkdir jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。"></a>2.使用命令cd /usr/lib，进入lib目录下，执行sudo mkdir jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。</h2><h2 id="3-回到先前解压安装包所在的目录，执行-sudo-mv命令，将解压文件夹移至jvm文件夹。如图"><a href="#3-回到先前解压安装包所在的目录，执行-sudo-mv命令，将解压文件夹移至jvm文件夹。如图" class="headerlink" title="3.回到先前解压安装包所在的目录，执行 sudo mv命令，将解压文件夹移至jvm文件夹。如图"></a>3.回到先前解压安装包所在的目录，执行 sudo mv命令，将解压文件夹移至jvm文件夹。如图</h2><p><img src="\images\pasted-3.png" alt="upload successful"></p><h2 id="4-执行sudo-gedit-etc-profile，进入profile文件，添加如下内容至文件尾"><a href="#4-执行sudo-gedit-etc-profile，进入profile文件，添加如下内容至文件尾" class="headerlink" title="4.执行sudo gedit etc/profile，进入profile文件，添加如下内容至文件尾"></a>4.执行sudo gedit etc/profile，进入profile文件，添加如下内容至文件尾</h2><p><img src="\images\pasted-4.png" alt="upload successful"><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_05   </span><br><span class="line">export JRE_HOME=$&#123;JAVA_HOME&#125;/jre    </span><br><span class="line">export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib    </span><br><span class="line">export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH</span><br></pre></td></tr></table></figure><p></p><h2 id="5-为了使配置直接生效，执行下图命令："><a href="#5-为了使配置直接生效，执行下图命令：" class="headerlink" title="5.为了使配置直接生效，执行下图命令："></a>5.为了使配置直接生效，执行下图命令：</h2><p><img src="\images\pasted-5.png" alt="upload successful"><br>这里如果不执行该命令，需要注销或重启，再次登陆后才能正确显示安装结果。</p><h2 id="6-验证JDK是否安装成功，执行java-version："><a href="#6-验证JDK是否安装成功，执行java-version：" class="headerlink" title="6.验证JDK是否安装成功，执行java -version："></a>6.验证JDK是否安装成功，执行java -version：</h2><p><img src="\images\pasted-6.png" alt="upload successful"><br>如果显示如图，则证明安装成功。</p><h1 id="三、新建hadoop用户并启用ssh免密登录"><a href="#三、新建hadoop用户并启用ssh免密登录" class="headerlink" title="三、新建hadoop用户并启用ssh免密登录"></a>三、新建hadoop用户并启用ssh免密登录</h1><p>这里我使用的是hadoop-2.6.0。</p><h2 id="1-新建hadoop用户，使用-bin-bash-作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。"><a href="#1-新建hadoop用户，使用-bin-bash-作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。" class="headerlink" title="1.新建hadoop用户，使用/bin/bash 作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。"></a>1.新建hadoop用户，使用/bin/bash 作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。</h2><p><img src="\images\pasted-7.png" alt="upload successful"></p><h2 id="2-安装并配置ssh"><a href="#2-安装并配置ssh" class="headerlink" title="2.安装并配置ssh"></a>2.安装并配置ssh</h2><p>1).Ubuntu默认安装了ssh client，但还需要安装ssh server，否则不能登录localhost，如下</p><p><img src="\images\pasted-8.png" alt="upload successful"><br>2).执行下图命令，安装ssh server，</p><p><img src="\images\pasted-9.png" alt="upload successful"><br>安装成功后可以登录localhost，不过需要输入密码，如下<br><img src="index_files/14182000.png" alt=""><br>使用exit命令退出登录。<br>3).执行ssh-keygen命令，生成密钥对，再进入.ssh目录，将新生成的公钥复制到已授权秘钥列表，如下</p><p><img src="\images\pasted-10.png" alt="upload successful"><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp .ssh/id_rsa.pub .ssh/authorized_keys</span><br></pre></td></tr></table></figure><p></p><p>此时再尝试登录会发现已经不用再输入密码了，配置完成。</p><p><img src="\images\pasted-11.png" alt="upload successful"></p><p>补充：</p><h3 id="1-这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在-ssh目录中。"><a href="#1-这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在-ssh目录中。" class="headerlink" title="1.这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在.ssh目录中。"></a>1.这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在.ssh目录中。</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#若不采用虚拟机克隆，则需在slave中建立.ssh目录，在slave中执行如下命令</span><br><span class="line">hadoop@slave1：~$ mkdir .ssh</span><br><span class="line"></span><br><span class="line">#在master中执行以下命令，复制认证文件（这里的认证文件已经添加过本机的公钥了）</span><br><span class="line">hadoop@master:~./ssh$ scp authorized_keys hadoop@ slave1:/home/hadoop/.ssh</span><br></pre></td></tr></table></figure><p>这样一来可以直接使用ssh slave1来无秘登录对方。</p><h3 id="2-配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录"><a href="#2-配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录" class="headerlink" title="2.配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录"></a>2.配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录</h3><p>#以下修改在master上，建议先备份sshd_config<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/ssh</span><br><span class="line">sudo cp sshd_config sshd_config.bak</span><br><span class="line">sudo nano sshd_config</span><br><span class="line">#将下列三句改为no，并将第三句注释去掉。</span><br><span class="line">PermitRootLogin yes</span><br><span class="line">UsePAM yes</span><br><span class="line">#PasswordAuthentication yes</span><br></pre></td></tr></table></figure><p></p><h2 id="3-仅允许一台或一些机器登录ssh服务器"><a href="#3-仅允许一台或一些机器登录ssh服务器" class="headerlink" title="3.仅允许一台或一些机器登录ssh服务器"></a>3.仅允许一台或一些机器登录ssh服务器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#仍在sshd_config中编辑，加入如下语句即可</span><br><span class="line">allowusers hadoop@192.168.1.2</span><br><span class="line">#以上意思为仅允许192.168.1.2上的hadoop用户登录ssh，保证安全</span><br><span class="line">#重启服务</span><br><span class="line">service ssh restart</span><br></pre></td></tr></table></figure><h1 id="四、安装并配置Hadoop"><a href="#四、安装并配置Hadoop" class="headerlink" title="四、安装并配置Hadoop"></a>四、安装并配置Hadoop</h1><h2 id="4-1-解压安装hadoop"><a href="#4-1-解压安装hadoop" class="headerlink" title="4.1 解压安装hadoop"></a>4.1 解压安装hadoop</h2><p>1).这里和安装JDK类似，我将其装在/usr/local目录下的hadoop文件夹中，不再详述。<br>2).配置环境变量<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit /etc/profile</span><br><span class="line">#添加以下内容至文件尾</span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br></pre></td></tr></table></figure><p></p><p>找到hadoop-env.sh文件，将其中的”export JAVA_HOME=”一句填入Java的安装目录,此次所用版本该文件在/usr/local/hadoop/etc/hadoop目录下，根据版本找到该文件即可。<br>可使用hadoop version命令查看版本，若按照成功则会提示版本信息。<br>3).启动hadoop<br>启动文件为start-all.sh，2.6中在sbin目录下。<br>4).运行jps<br>可以查看有没有java进程在运行，正常状况下可以见到 xxx Jps 字样的提示。<br>5).结束hadoop<br>结束文件stop-all.sh。</p><h2 id="4-2配置伪分布模式"><a href="#4-2配置伪分布模式" class="headerlink" title="4.2配置伪分布模式"></a>4.2配置伪分布模式</h2><p>1).修改core-site.xml文件<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit ./etc/hadoop/core-site.xml</span><br><span class="line">#改为如下内容</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;</span><br><span class="line">             &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p></p><p>2).修改hdfs-site.xml文件<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit ./etc/hadoop/core-site.xml</span><br><span class="line">#改为如下内容</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p></p><p>（本段摘自网络）</p><blockquote><p>Hadoop配置文件说明<br>Hadoop 的运行方式是由配置文件决定的（运行 Hadoop 时会读取配置文件），因此如果需要从伪分布式模式切换回非分布式模式，需要删除 core-site.xml 中的配置项。此外，伪分布式虽然只需要配置 fs.defaultFS 和 dfs.replication 就可以运行（官方教程如此），不过若没有配置 hadoop.tmp.dir 参数，则默认使用的临时目录为 /tmp/hadoo-hadoop，而这个目录在重启时有可能被系统清理掉，导致必须重新执行 format 才行。所以我们进行了设置，同时也指定 dfs.namenode.name.dir 和 dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。</p></blockquote><p>3).格式化<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode -format</span><br></pre></td></tr></table></figure><p></p><p>4).启动hadoop（略）<br>5).运行Jps查看，若开启成功，则有如下提示</p><p><img src="\images\pasted-12.png" alt="upload successful"><br>6).关闭hadoop（略）</p><h1 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h1><p>安装过程中遇到了很多问题，通过网络及书籍等参考解决了大部分问题，水平有限，若有其他问题请联系我。<br>本次安装后对几个问题的理解：</p><h1 id="1-hadoop用户是必须建立的吗？"><a href="#1-hadoop用户是必须建立的吗？" class="headerlink" title="1.hadoop用户是必须建立的吗？"></a>1.hadoop用户是必须建立的吗？</h1><p>其实是非必要的，但是建议做。直接在默认用户上按照上述内容进行操作（省去建立用户即可），也可以完成配置。这里建议做的原因有两个：其一是为了方便配置，如果在默认用户上进行安装，有些文件夹（比如hadoop）的所有权在root上，会影响后续的格式化过程，可以修改文件夹权限来解决；其二是本着专用的原则，所有处理Hadoop的内容均在hadoop用户上进行，别的系统不会影响到本系统，反之亦然。</p><h1 id="2-关于SSH配置的用途"><a href="#2-关于SSH配置的用途" class="headerlink" title="2.关于SSH配置的用途"></a>2.关于SSH配置的用途</h1><p>最近本人在折腾路由器，用到了不少远程管理工具（putty，winSCP，SecureCRT），但路由器端必须开启ssh或talnet等。这里hadoop集群中主机也需要远程登录其他机器，来进行相关操作，因此必须配置相关内容，并且也能方便后续管理。</p><p>参考资料：</p><ol><li><p><a href="http://www.powerxing.com/install-hadoop/" target="_blank" rel="noopener">http://www.powerxing.com/install-hadoop/</a></p></li><li><p>《实战Hadoop大数据处理》，曾刚</p></li><li><p>《Hadoop基础教程》，Garry Turkington</p></li></ol><p>以上2016年11月28日 星期一 22:19:50</p></div><div><div><div style="text-align:center;color:#ccc;font-size:14px">-------------本文结束<i class="fa fa-heart"></i>感谢您的阅读-------------</div></div></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div>请作者喝冰阔落~</div><button id="rewardButton" disable="enable" onclick='var e=document.getElementById("QR");"none"===e.style.display?e.style.display="block":e.style.display="none"'><span>打赏</span></button><div id="QR" style="display:none"><div id="wechat" style="display:inline-block"><img id="wechat_qr" src="/images/wechatpay.jpg" alt="co1de 微信支付"><p>微信支付</p></div><div id="alipay" style="display:inline-block"><img id="alipay_qr" src="/images/alipay.jpg" alt="co1de 支付宝"><p>支付宝</p></div></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Hadoop环境搭建/" rel="tag"><i class="fa fa-tag"></i> Hadoop环境搭建</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2019/03/03/常用git命令记录/" rel="next" title="常用git命令记录"><i class="fa fa-chevron-left"></i> 常用git命令记录</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"></div></div></footer></div></article></div></div><div class="comments" id="comments"></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><div class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/run.jpg" alt="co1de"><p class="site-author-name" itemprop="name">co1de</p><p class="site-description motion-element" itemprop="description">保持好奇心，提高行动力</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">4</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">2</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">2</span> <span class="site-state-item-name">标签</span></a></div></nav></div></div><div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。"><span class="nav-number">1.</span> <span class="nav-text">最近整理文档，发现了一些旧的笔记，放在这里鞭尸一下。</span></a></li></ol><li class="nav-item nav-level-1"><a class="nav-link" href="#一、在虚拟机中安装Ubuntu"><span class="nav-number"></span> <span class="nav-text">一、在虚拟机中安装Ubuntu</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192-168-1-0-完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192-168-1-2-255-255-255-0"><span class="nav-number">1.</span> <span class="nav-text">1. vm中vmnet1是仅主机模式，从“编辑”菜单中的虚拟网络编辑器中进入，将DHCP功能关闭，子网ip处填入设定的网段。本次使用的为192.168.1.0.完毕后在宿主机的网络连接管理中找到VMnet1，指定相应的ip与掩码，这里使用的是192.168.1.2 255.255.255.0</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192-168-1-10）。或修改-etc-network-interfaces目录，在最后补充如下内容"><span class="nav-number">2.</span> <span class="nav-text">2.进入虚拟机后对虚拟机网络进行设置，由于使用的系统为Ubuntu，可以采用窗口操作，直接将ip地址填写即可（注意要在同一网段，本次Master使用为192.168.1.10）。或修改/etc/network/interfaces目录，在最后补充如下内容</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-可在宿主机运行cmd，在控制台进行ping命令，若能ping通192-168-1-10，则配置完成。"><span class="nav-number">3.</span> <span class="nav-text">3.可在宿主机运行cmd，在控制台进行ping命令，若能ping通192.168.1.10，则配置完成。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-对第一台虚拟机进行重命名，文件在-etc-hostname下，本次设定为Master。之后需要在-etc-hosts文件中将127-0-0-1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。"><span class="nav-number">4.</span> <span class="nav-text">4.对第一台虚拟机进行重命名，文件在/etc/hostname下，本次设定为Master。之后需要在/etc/hosts文件中将127.0.0.1（即本机）后的名字进行相应修改，否则会出现无法解析主机等问题。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192-168-1-20），并进行重命名（slave1）。"><span class="nav-number">5.</span> <span class="nav-text">5.在vm中采用克隆功能，建立其他虚拟机，并采用上述同样步骤指定ip（192.168.1.20），并进行重命名（slave1）。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。"><span class="nav-number">6.</span> <span class="nav-text">6.指定成功可在宿主机ping通master和slave1，且master和slave1之间也能互相ping通。</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#二、配置Java开发环境（安装JDK）"><span class="nav-number"></span> <span class="nav-text">二、配置Java开发环境（安装JDK）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-一般从网上下载会放在‘下载’位置下，我将它放在桌面上。"><span class="nav-number">1.</span> <span class="nav-text">1.一般从网上下载会放在‘下载’位置下，我将它放在桌面上。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-使用命令cd-usr-lib，进入lib目录下，执行sudo-mkdir-jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。"><span class="nav-number">2.</span> <span class="nav-text">2.使用命令cd /usr/lib，进入lib目录下，执行sudo mkdir jvm，建立jvm文件夹。这里必须使用sudo，图形化界面无法新建文件夹，权限不够。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-回到先前解压安装包所在的目录，执行-sudo-mv命令，将解压文件夹移至jvm文件夹。如图"><span class="nav-number">3.</span> <span class="nav-text">3.回到先前解压安装包所在的目录，执行 sudo mv命令，将解压文件夹移至jvm文件夹。如图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-执行sudo-gedit-etc-profile，进入profile文件，添加如下内容至文件尾"><span class="nav-number">4.</span> <span class="nav-text">4.执行sudo gedit etc/profile，进入profile文件，添加如下内容至文件尾</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-为了使配置直接生效，执行下图命令："><span class="nav-number">5.</span> <span class="nav-text">5.为了使配置直接生效，执行下图命令：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-验证JDK是否安装成功，执行java-version："><span class="nav-number">6.</span> <span class="nav-text">6.验证JDK是否安装成功，执行java -version：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#三、新建hadoop用户并启用ssh免密登录"><span class="nav-number"></span> <span class="nav-text">三、新建hadoop用户并启用ssh免密登录</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-新建hadoop用户，使用-bin-bash-作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。"><span class="nav-number">1.</span> <span class="nav-text">1.新建hadoop用户，使用/bin/bash 作为shell，并设置登录密码。为防止出现权限问题，将hadoop加入sudo用户组。之后注销当前用户，用hadoop用户登录。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-安装并配置ssh"><span class="nav-number">2.</span> <span class="nav-text">2.安装并配置ssh</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在-ssh目录中。"><span class="nav-number">2.1.</span> <span class="nav-text">1.这里若想直接登录slave1，可将master生成的秘钥复制给对方，或是在所有过程完毕后直接克隆master改名成slave1。后者是复制的，所以master的公钥自然在.ssh目录中。</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录"><span class="nav-number">2.2.</span> <span class="nav-text">2.配置ssh服务器，使客户端不能使用密码登录，只能使用公钥登录</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-仅允许一台或一些机器登录ssh服务器"><span class="nav-number">3.</span> <span class="nav-text">3.仅允许一台或一些机器登录ssh服务器</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#四、安装并配置Hadoop"><span class="nav-number"></span> <span class="nav-text">四、安装并配置Hadoop</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-解压安装hadoop"><span class="nav-number">1.</span> <span class="nav-text">4.1 解压安装hadoop</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2配置伪分布模式"><span class="nav-number">2.</span> <span class="nav-text">4.2配置伪分布模式</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#总结："><span class="nav-number"></span> <span class="nav-text">总结：</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-hadoop用户是必须建立的吗？"><span class="nav-number"></span> <span class="nav-text">1.hadoop用户是必须建立的吗？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-关于SSH配置的用途"><span class="nav-number"></span> <span class="nav-text">2.关于SSH配置的用途</span></a></li></div></div></div></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2019</span> <span class="with-love" id="animate"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">co1de</span></div><span id="busuanzi_container_site_pv" class="theme-info">&nbsp;&nbsp;&nbsp;&nbsp;本站总访问量<span id="busuanzi_value_site_pv"></span>次 </span><span id="busuanzi_container_site_uv" class="theme-info">&nbsp;&nbsp;|&nbsp;&nbsp;本站访客数<span id="busuanzi_value_site_uv"></span>人次</span><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script>"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="/lib/canvas-nest/canvas-nest.min.js"></script><script src="/lib/jquery/index.js?v=2.1.3"></script><script src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script src="/js/src/utils.js?v=6.7.0"></script><script src="/js/src/motion.js?v=6.7.0"></script><script src="/js/src/affix.js?v=6.7.0"></script><script src="/js/src/schemes/pisces.js?v=6.7.0"></script><script src="/js/src/scrollspy.js?v=6.7.0"></script><script src="/js/src/post-details.js?v=6.7.0"></script><script src="/js/src/bootstrap.js?v=6.7.0"></script><script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script><script src="//unpkg.com/valine/dist/Valine.min.js"></script><script>var GUEST=["nick","mail","link"],guest="nick,mail,link";guest=guest.split(",").filter(function(e){return GUEST.indexOf(e)>-1}),new Valine({el:"#comments",verify:!1,notify:!1,appId:"XzkPRbve0eqeGrw5ijtR6uAT-gzGzoHsz",appKey:"mMouJAbT2QcNCH6RguUB9Lnt",placeholder:"Just go go",avatar:"mm",meta:guest,pageSize:"10",visitor:!1})</script><script>function addCount(Counter) {
      var $visitors = $('.leancloud_visitors');
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text(counter.time + 1);
            
            Counter('put', '/classes/Counter/' + counter.objectId, JSON.stringify({ time: { '__op': 'Increment', 'amount': 1 } }))
            
              .fail(function ({ responseJSON }) {
                console.log(`Failed to save Visitor num, with error message: ${responseJSON.error}`);
              })
          } else {
            
              Counter('post', '/classes/Counter', JSON.stringify({ title: title, url: url, time: 1 }))
                .done(function() {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(1);
                })
                .fail(function() {
                  console.log('Failed to create');
                });
            
          }
        })
        .fail(function ({ responseJSON }) {
          console.log(`LeanCloud Counter Error: ${responseJSON.code} ${responseJSON.error}`);
        });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + 'XzkPRbve0eqeGrw5ijtR6uAT-gzGzoHsz')
        .done(function({ api_server }) {
          var Counter = function(method, url, data) {
            return $.ajax({
              method: method,
              url: 'https://' + api_server + '/1.1' + url,
              headers: {
                'X-LC-Id': 'XzkPRbve0eqeGrw5ijtR6uAT-gzGzoHsz',
                'X-LC-Key': 'mMouJAbT2QcNCH6RguUB9Lnt',
                'Content-Type': 'application/json',
              },
              data: data
            });
          };
          
            addCount(Counter);
          
        });
    });</script><script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script><script type="text/javascript" src="/js/src/clicklove.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({enabled:!0,tagMode:!0,display:{position:"right",width:75,height:150},mobile:{show:!1},log:!1,pluginJsPath:"lib/",pluginModelPath:"assets/",pluginRootPath:"live2dw/"})</script></body></html><!-- rebuild by neat -->